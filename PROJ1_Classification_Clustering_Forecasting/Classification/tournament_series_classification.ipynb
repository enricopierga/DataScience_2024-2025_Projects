{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparazione dati e filtraggio match International, International Gold, Masters, Masters Cup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dati\n",
    "df = pd.read_csv('./atp_tennis.csv')\n",
    "\n",
    "# Salva il numero originale di righe\n",
    "original_rows = len(df)\n",
    "\n",
    "# Filtra ranking e punti negativi o nulli\n",
    "rows_before = len(df)\n",
    "df = df[\n",
    "    (df['Rank_1'] > 0) & \n",
    "    (df['Rank_2'] > 0) & \n",
    "    (df['Pts_1'] > 0) & \n",
    "    (df['Pts_2'] > 0)\n",
    "]\n",
    "rows_after = len(df)\n",
    "print(f\"\\nRighe rimosse per ranking o punti non validi: {rows_before - rows_after}\")\n",
    "\n",
    "# Mostra distribuzione originale delle categorie\n",
    "print(\"\\nDistribuzione originale delle categorie dei tornei:\")\n",
    "print(df['Series'].value_counts())\n",
    "print(\"\\nDistribuzione originale dei Round:\")\n",
    "print(df['Round'].value_counts())\n",
    "\n",
    "# Filtra le categorie non rilevanti dal target\n",
    "rows_before_series = len(df)\n",
    "df = df[~df['Series'].isin(['International', 'International Gold', 'Masters', 'Masters Cup'])]\n",
    "rows_after_series = len(df)\n",
    "\n",
    "print(f\"\\nRighe rimosse dal filtraggio delle Series: {rows_before_series - rows_after_series}\")\n",
    "print(\"Categorie rimosse:\")\n",
    "for category in ['International', 'International Gold', 'Masters', 'Masters Cup']:\n",
    "    count = len(df[df['Series'] == category])\n",
    "    print(f\"- {category}: {count} partite\")\n",
    "\n",
    "# Mostra distribuzione delle categorie dopo il filtraggio delle Series\n",
    "print(\"\\nDistribuzione delle categorie dei tornei dopo il filtraggio delle Series:\")\n",
    "print(df['Series'].value_counts())\n",
    "\n",
    "# Filtra Round Robin\n",
    "rows_before_round = len(df)\n",
    "df = df[df['Round'] != 'Round Robin']\n",
    "rows_after_round = len(df)\n",
    "\n",
    "print(f\"\\nRighe rimosse dal filtraggio del Round: {rows_before_round - rows_after_round}\")\n",
    "print(f\"- Round Robin: {rows_before_round - rows_after_round} partite\")\n",
    "\n",
    "# Mostra distribuzione dei Round dopo il filtraggio\n",
    "print(\"\\nDistribuzione dei Round dopo il filtraggio del Round Robin:\")\n",
    "print(df['Round'].value_counts())\n",
    "\n",
    "# Riepilogo finale\n",
    "print(\"\\nRiepilogo del filtraggio:\")\n",
    "print(f\"Righe originali: {original_rows}\")\n",
    "print(f\"Righe dopo filtraggio Series: {rows_after_series}\")\n",
    "print(f\"Righe dopo filtraggio Round: {rows_after_round}\")\n",
    "print(f\"Totale righe rimosse: {original_rows - len(df)}\")\n",
    "print(f\"Percentuale dati mantenuti: {(len(df)/original_rows)*100:.2f}%\")\n",
    "\n",
    "# Feature basata su Best_of e Grand Slam\n",
    "df['is_best_of_5'] = (df['Best of'] == 5).astype(int)\n",
    "df['is_grand_slam'] = df['is_best_of_5']\n",
    "\n",
    "# Feature basate sul Winner e ranking\n",
    "df['winner_rank'] = df.apply(lambda x: x['Rank_1'] if x['Winner'] == 1 else x['Rank_2'], axis=1)\n",
    "df['rank_diff'] = abs(df['Rank_1'] - df['Rank_2'])\n",
    "df['avg_rank'] = (df['Rank_1'] + df['Rank_2']) / 2\n",
    "\n",
    "# Feature basate sul Round\n",
    "round_mapping = {\n",
    "    '1st Round': 1,\n",
    "    '2nd Round': 2,\n",
    "    '3rd Round': 3,\n",
    "    '4th Round': 4,\n",
    "    'Quarterfinals': 5,\n",
    "    'Semifinals': 6,\n",
    "    'The Final': 7\n",
    "}\n",
    "\n",
    "# Converti il Round in numero e calcola dimensione tabellone\n",
    "df['round_number'] = df['Round'].map(round_mapping)\n",
    "df['has_3rd_round'] = (df['Round'].isin(['3rd Round', '4th Round'])).astype(int)\n",
    "# Calcola dimensione tabellone con controllo sul tipo di torneo\n",
    "df['draw_size'] = df.apply(lambda x: \n",
    "    128 if x['Round'] == '4th Round' else  # Grand Slam e alcuni Masters 1000\n",
    "    96 if x['has_3rd_round'] == 1 and x['Series'] == 'Masters 1000' else  # Solo Masters 1000\n",
    "    64 if x['Round'] == '3rd Round' else    # ATP 500\n",
    "    32,                                     # ATP 250\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilanciamento dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa il dataset per categoria\n",
    "df_250 = df[df['Series'] == 'ATP250']\n",
    "df_500 = df[df['Series'] == 'ATP500']\n",
    "df_1000 = df[df['Series'] == 'Masters 1000']\n",
    "df_slam = df[df['Series'] == 'Grand Slam']\n",
    "\n",
    "# Determina la dimensione target (usiamo la categoria con meno esempi)\n",
    "n_samples = min(len(df_500), len(df_1000), len(df_slam))\n",
    "\n",
    "# Downsampling della classe maggioritaria (ATP250)\n",
    "df_250_balanced = resample(df_250,\n",
    "                         replace=False,\n",
    "                         n_samples=n_samples,\n",
    "                         random_state=42)\n",
    "\n",
    "# Mantieni le altre classi invariate se hanno gi√† circa n_samples elementi\n",
    "# altrimenti fai upsampling\n",
    "df_500_balanced = resample(df_500,\n",
    "                         replace=True,\n",
    "                         n_samples=n_samples,\n",
    "                         random_state=42)\n",
    "\n",
    "df_1000_balanced = resample(df_1000,\n",
    "                          replace=True,\n",
    "                          n_samples=n_samples,\n",
    "                          random_state=42)\n",
    "\n",
    "df_slam_balanced = resample(df_slam,\n",
    "                          replace=True,\n",
    "                          n_samples=n_samples,\n",
    "                          random_state=42)\n",
    "\n",
    "# Combina i dataset bilanciati\n",
    "df_balanced = pd.concat([df_250_balanced, \n",
    "                        df_500_balanced,\n",
    "                        df_1000_balanced,\n",
    "                        df_slam_balanced])\n",
    "\n",
    "# Controlla la distribuzione delle classi nel dataset bilanciato\n",
    "print(\"Distribuzione delle classi nel dataset bilanciato:\")\n",
    "print(df_balanced['Series'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola il ranking medio per categoria del torneo\n",
    "ranking_medio = df_balanced.groupby('Series')['avg_rank'].mean()\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Ranking medio per categoria del torneo:\")\n",
    "print(ranking_medio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparazione features per classificazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparazione features iniziali\n",
    "features = ['Round']  # Solo Round come feature categorica\n",
    "\n",
    "# Codifica variabili categoriche\n",
    "le = LabelEncoder()\n",
    "df_balanced['Round'] = le.fit_transform(df_balanced['Round'])\n",
    "print(f\"\\nCategorie per Round: {le.classes_}\")\n",
    "\n",
    "# Codifica della variabile target\n",
    "target = 'Series'\n",
    "df_balanced['Series_encoded'] = le.fit_transform(df_balanced[target])\n",
    "print(f\"\\nCategorie per Series: {le.classes_}\")\n",
    "\n",
    "# Aggiorna la lista delle features, organizzate per importanza e tipologia\n",
    "features.extend([\n",
    "    # Feature strutturali del torneo   \n",
    "    'draw_size',\n",
    "    'round_number',\n",
    "    \n",
    "    # Feature di ranking\n",
    "    'Rank_1', 'Rank_2',\n",
    "    'rank_diff',\n",
    "    'winner_rank',\n",
    "    'is_best_of_5',\n",
    "    \n",
    "    # Feature di punti\n",
    "    'Pts_1', 'Pts_2'\n",
    "])\n",
    "\n",
    "# Preparazione dati usando il dataset bilanciato\n",
    "X = df_balanced[features].copy()\n",
    "y = le.fit_transform(df_balanced[target])\n",
    "\n",
    "print(X.head(20))\n",
    "\n",
    "# Standardizzazione delle feature numeriche\n",
    "numeric_features = [col for col in features if col != 'Round']\n",
    "\n",
    "# Converti le colonne numeriche in float64 prima della standardizzazione\n",
    "for feature in numeric_features:\n",
    "    X[feature] = X[feature].astype('float64')\n",
    "\n",
    "# Applica la standardizzazione\n",
    "scaler = StandardScaler()\n",
    "X.loc[:, numeric_features] = scaler.fit_transform(X[numeric_features])\n",
    "\n",
    "# Split dei dati\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Controlla la distribuzione delle classi nel dataset finale\n",
    "print(\"\\nDistribuzione delle classi nel dataset finale:\")\n",
    "print(pd.Series(y).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calcolo della matrice di correlazione\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "# Plot della heatmap della matrice di correlazione\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", vmin=-1, vmax=1)\n",
    "plt.title(\"Heatmap della matrice di correlazione tra le feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento e valutazione modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dizionario dei classificatori\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Valutazione dei modelli\n",
    "results = {}\n",
    "\n",
    "# Dizionario dei classificatori\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(\n",
    "        kernel='rbf',  # Cambia il kernel\n",
    "        C=10.0,        # Aumenta C per ridurre la regolarizzazione\n",
    "        gamma='scale', \n",
    "        random_state=42\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Assicurati che i dati siano scalati correttamente prima del ciclo\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Valutazione dei modelli\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\n{'-'*50}\")\n",
    "    print(f\"Valutazione del classificatore: {name}\")\n",
    "    \n",
    "    # Addestramento\n",
    "    if name == 'SVM':\n",
    "        # Usa i dati scalati per SVM\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "    else:\n",
    "        # Per gli altri classificatori usa i dati originali\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Salvataggio risultati\n",
    "    results[name] = {\n",
    "        'classification_report': classification_report(y_test, y_pred),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    # Report di classificazione\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(results[name]['classification_report'])\n",
    "    \n",
    "    # Matrice di confusione\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = results[name]['confusion_matrix']\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=le.classes_,\n",
    "                yticklabels=le.classes_)\n",
    "    plt.title(f'Matrice di Confusione - {name}')\n",
    "    plt.ylabel('Valore Reale')\n",
    "    plt.xlabel('Valore Predetto')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Feature importance per Random Forest e Gradient Boosting\n",
    "    if name in ['Random Forest', 'Gradient Boosting']:\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': features,\n",
    "            'importance': clf.feature_importances_\n",
    "        })\n",
    "        feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "        plt.title(f'Importanza delle Feature - {name}')\n",
    "        plt.xlabel('Importanza')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nImportanza delle feature in percentuale:\")\n",
    "        for idx, row in feature_importance.iterrows():\n",
    "            print(f\"{row['feature']}: {row['importance']*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confronto delle performance\n",
    "performances = []\n",
    "for name, result in results.items():\n",
    "    report = classification_report(y_test, classifiers[name].predict(X_test), output_dict=True)\n",
    "    performances.append({\n",
    "        'Classificatore': name,\n",
    "        'Accuracy': report['accuracy'],\n",
    "        'Macro F1-Score': report['macro avg']['f1-score']\n",
    "    })\n",
    "\n",
    "# Visualizzazione confronto performance\n",
    "performance_df = pd.DataFrame(performances)\n",
    "plt.figure(figsize=(12, 6))\n",
    "performance_df.plot(x='Classificatore', y=['Accuracy', 'Macro F1-Score'], kind='bar')\n",
    "plt.title('Confronto Performance Classificatori')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTabella delle Performance:\")\n",
    "print(performance_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
